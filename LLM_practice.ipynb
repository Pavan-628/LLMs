{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain_experimental.pal_chain import PALChain\n",
    "from langchain.chains import SimpleSequentialChain,SequentialChain\n",
    "from langchain.memory import SimpleMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a good name for a company that makes podcast player?\n"
     ]
    }
   ],
   "source": [
    "prompt=PromptTemplate(\n",
    "    input_variables=['product'],\n",
    "    template=\"What is a good name for a company that makes {product}?\",\n",
    ")\n",
    "\n",
    "print(prompt.format(product=\"podcast player\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nPodJogger.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=OpenAI(\n",
    "    model_name=\"text-davinci-003\",\n",
    "    temperature=0.9)\n",
    "llmchain=LLMChain(llm=llm,prompt=prompt)\n",
    "llmchain.run(\"podcast player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PodcastPro'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chatopenai=ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\")\n",
    "llmchain_chat=LLMChain(llm=chatopenai,prompt=prompt)\n",
    "llmchain_chat.run(\"podcast player\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new PALChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python REPL can execute arbitrary code. Use with caution.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mdef solution():\n",
      "    \"\"\"if my age is half of my dad's age and he is going to be 60 next year,what is my current age?\"\"\"\n",
      "    dad_age_now = 59\n",
      "    my_age_now = dad_age_now / 2\n",
      "    result = my_age_now\n",
      "    return result\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'29.5'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palchain=PALChain.from_math_prompt(llm=llm,verbose=True)\n",
    "palchain.run(\"if my age is half of my dad's age and he is going to be 60 next year,what is my current age?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Chain.prep_inputs() missing 1 required positional argument: 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\DS\\LLMs\\LLM_practice.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/DS/LLMs/LLM_practice.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(palchain\u001b[39m.\u001b[39;49mprep_inputs())\n",
      "\u001b[1;31mTypeError\u001b[0m: Chain.prep_inputs() missing 1 required positional argument: 'inputs'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to know the age difference between my dad and I\n",
      "Action: Calculator\n",
      "Action Input: 60 - half of 60\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIError: Request failed due to server shutdown {\n",
      "  \"error\": {\n",
      "    \"message\": \"Request failed due to server shutdown\",\n",
      "    \"type\": \"server_error\",\n",
      "    \"param\": null,\n",
      "    \"code\": null\n",
      "  }\n",
      "}\n",
      " 500 {'error': {'message': 'Request failed due to server shutdown', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 26 Sep 2023 16:52:02 GMT', 'Content-Type': 'application/json', 'Content-Length': '141', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'text-davinci-003', 'openai-organization': 'user-ockh9u2vxdxb3rveeylzyzgb', 'openai-processing-ms': '10419', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '3000', 'x-ratelimit-limit-tokens': '250000', 'x-ratelimit-limit-tokens_usage_based': '250000', 'x-ratelimit-remaining-requests': '2999', 'x-ratelimit-remaining-tokens': '249744', 'x-ratelimit-remaining-tokens_usage_based': '249744', 'x-ratelimit-reset-requests': '20ms', 'x-ratelimit-reset-tokens': '61ms', 'x-ratelimit-reset-tokens_usage_based': '61ms', 'x-request-id': '44ede517c28aa9a20748bb269f5af881', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '80cd0396985d17aa-MAA', 'alt-svc': 'h3=\":443\"; ma=86400'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 30.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know my dad's age and half of his age\n",
      "Action: Calculator\n",
      "Action Input: 30 / 2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 15.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know my current age\n",
      "Final Answer: 15\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'15'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm=OpenAI(temperature=0.9)\n",
    "tools=load_tools([\"llm-math\"],llm=llm)  #used llm-math instead of pal-math. it seems like pal-math is dropped from avaialble tools in langchain tools\n",
    "\n",
    "agent=initialize_agent(tools,\n",
    "                       llm,\n",
    "                       agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "                       verbose=True)\n",
    "\n",
    "agent.run(\"if my age is half of my dad's age and he is going to be 60 next year,what is my current age?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Calculating my dad's age will tell me my age.\n",
      "Action: Calculator\n",
      "Action Input: Demi Moore's age (57) + 1\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 58\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should divide by 2 to figure out my age\n",
      "Action: Calculator \n",
      "Action Input: 58/2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 29.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: My current age is 29.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'My current age is 29.'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run(\"My age is half of my dad's age. Next year he is going to be same age as Demi Moore. What is my current age?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chain1 - solve math problem, get the age\n",
    "chainone=agent\n",
    "\n",
    "#Chain2 - suggest age-appropriate gift\n",
    "template=\"\"\"You are a gift recomender. Giev a person's age,\\n\n",
    "it is your job to suggest an appropriate gift for them.\n",
    "\n",
    "Person Age:\n",
    "{age}\n",
    "Suggest gift:\"\"\"\n",
    "\n",
    "prompt_template=PromptTemplate(input_variables=[\"age\"],template=template)\n",
    "chaintwo=LLMChain(llm=llm,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain=SimpleSequentialChain(\n",
    "    chains=[chainone,chaintwo],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I know my dad's age is going to be 60 next year, which means his current age is 59.\n",
      "Thought: If my age is half of his current age, then my age must be half of 59.\n",
      "Action: Calculator\n",
      "Action Input: 59/2\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 29.5\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: My current age is 29.5 years old.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mMy current age is 29.5 years old.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m \n",
      "A great gift idea for someone of this age would be a gift card for a new experience such as an adventure outing, a cooking class, a tasting event, or a subscription box service. This will give them the opportunity to explore and try something new, creating memories that will last a lifetime.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' \\nA great gift idea for someone of this age would be a gift card for a new experience such as an adventure outing, a cooking class, a tasting event, or a subscription box service. This will give them the opportunity to explore and try something new, creating memories that will last a lifetime.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"if my age is half of my dad's age and he is going to be 60 next year,what is my current age?\"\n",
    "overall_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a gift recommender. Given a person's age,\\n\n",
    " it is your job to suggest an appropriate gift for them. If age is under 10,\\n\n",
    " the gift should cost no more than {budget} otherwise it should cost atleast 10 times {budget}.\n",
    "\n",
    " Person Age:\n",
    " {output}\n",
    " Suggest gift:\"\"\"\n",
    "prompt_template=PromptTemplate(input_variables=[\"output\",'budget'],template=template)\n",
    "chaintwo=LLMChain(llm=llm,prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['text']\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.output_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain=SequentialChain(\n",
    "    input_variables=[\"input\"],\n",
    "    memory=SimpleMemory(memories={\"budget\":\"100 GBP\"}),\n",
    "    chains=[agent,chaintwo],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing input variables to the SequentialChain is mandatory unlike SimpleSequentialChain. it is the list of input variables expected by the first entity in the chain. Here it our agent.\n",
    "We can find the name of the variable used in the input prompt that the agent is using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the following questions as best you can. You have access to the following tools:\n",
      "\n",
      "Calculator: Useful for when you need to answer questions about math.\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: the input question you must answer\n",
      "Thought: you should always think about what to do\n",
      "Action: the action to take, should be one of [Calculator]\n",
      "Action Input: the input to the action\n",
      "Observation: the result of the action\n",
      "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
      "Thought: I now know the final answer\n",
      "Final Answer: the final answer to the original input question\n",
      "\n",
      "Begin!\n",
      "\n",
      "Question: {input}\n",
      "Thought:{agent_scratchpad}\n"
     ]
    }
   ],
   "source": [
    "print(agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end we can see that the questions being asked are stored in the variable input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['input', 'agent_scratchpad']\n"
     ]
    }
   ],
   "source": [
    "#the variable name can also be found like this\n",
    "print(agent.agent.llm_chain.prompt.input_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SimpleMEmory is an easy way of storing context and other information that shouldnt change between prompts. It requires one parameter at the time of initialization - memories. you can pass elements to it dict form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m I need to solve for x.\n",
      "Action: Calculator\n",
      "Action Input: .5x+1=60\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mAnswer: 29.5\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m I now know the final answer\n",
      "Final Answer: My current age is 29.5.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nGiven your age, I would suggest a gift that is at least Â£1000. Some potential ideas could be a set of designer luggage, a smartwatch, a digital camera, a gaming console, a smart home device, or a luxury spa treatment.'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question=\"if my age is half of my dad's age and he is going to be 60 next year,what is my current age?\"\n",
    "overall_chain.run(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
