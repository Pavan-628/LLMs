{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import  WebBaseLoader\n",
    "from langchain.chains.summarize import load_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm=ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader=WebBaseLoader(\"https://github.com/facebookresearch//llama\")\n",
    "#loader=WebBaseLoader(\"https://towardsdatascience.com/a-practical-introduction-to-llms-65194dda1148\")\n",
    "chain=load_summarize_chain(llm,chain_type='stuff')\n",
    "docs=loader.load()\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The GitHub repository for the LLaMA project by Facebook Research contains inference code, pretrained models, fine-tuned chat models, and examples for running inference locally. It also offers downloads for models and tokenizers from the Meta website or access to them on Hugging Face. The repository provides information on model usage, model card, license, and references.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=WebBaseLoader(\"https://github.com/facebookresearch//llama\")\n",
    "chain=load_summarize_chain(llm,chain_type='map_reduce')\n",
    "docs=loader.load()\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The GitHub repository \"facebookresearch/llama\" contains the inference code for LLaMA models. The repository provides models and code for language models ranging from 7B to 70B parameters. Users can download the models and run them locally for inference. The repository also includes fine-tuned chat models and provides instructions for running them. The models are licensed for use by researchers and commercial entities. The repository has received 42.6k stars and has been forked 7.1k times.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=WebBaseLoader(\"https://github.com/facebookresearch//llama\")\n",
    "chain=load_summarize_chain(llm,chain_type='refine')\n",
    "docs=loader.load()\n",
    "chain.run(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LLM_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
